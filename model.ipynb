{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulsingh/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rahulsingh/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "from transformers import LongformerTokenizer, LongformerModel\n",
    "import torch\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Longformer model and tokenizer\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-large-4096')\n",
    "model = LongformerModel.from_pretrained('allenai/longformer-large-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom embedding class with embed_query method\n",
    "class LongformerEmbedding:\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=4096, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().tolist()  # Mean pooling\n",
    "        return embedding\n",
    "\n",
    "# Instantiate the custom embedding class\n",
    "longformer_embedder = LongformerEmbedding(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Pinecone and initialize with the existing index\n",
    "index_name = \"hubspot-crm-txts\"\n",
    "\n",
    "# Initialize PineconeVectorStore with the custom embedding class\n",
    "vector_store = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=longformer_embedder  # Pass the embedding class here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Retrieval Chain with LangChain\n",
    "llm_rag = ChatAnthropic(model='claude-3-5-sonnet-20241022', temperature=0.1)\n",
    "\n",
    "# Define your custom prompt with context and prefix\n",
    "rag_template = \"\"\"\n",
    "Role: HubSpot code generator that prioritizes context-provided information.\n",
    "\n",
    "Context: {text}\n",
    "\n",
    "Generate Python code for HubSpot API operations that:\n",
    "- Uses HubSpot Client Library when possible, falls back to requests library for associations\n",
    "- Returns raw JSON responses (no parsing)\n",
    "- Includes proper error handling\n",
    "- Uses provided access_token\n",
    "- Includes necessary imports\n",
    "- Ends with print(response)\n",
    "\n",
    "For filtering:\n",
    "- Use HubSpot Filter objects with correct imports\n",
    "- Match filter properties to object type\n",
    "\n",
    "Code requirements:\n",
    "- No comments/docstrings\n",
    "- No syntax blocks\n",
    "- No explanations\n",
    "- Try-except wrapped\n",
    "- Raw response only\n",
    "\n",
    "For associations:\n",
    "- Use requests.get() with proper endpoints\n",
    "- Format: api.hubapi.com/crm/v4/objects/<object_type>/<id>/associations/<to_object_type>\n",
    "- Include Authorization header with Bearer token\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate(template=rag_template, input_variables=[\"text\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Retrieval-Augmented Generation (RAG) chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_rag,\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs = {\n",
    "        \"prompt\": rag_prompt,\n",
    "        \"document_variable_name\": \"text\"\n",
    "    },   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the RAG Chain\n",
    "query = \"what contacts are associated to the deal with id = 28338118010? my access token is pat-na1-59c263ed-698c-4077-b2bc-d1e001750420\"\n",
    "response = rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup simple llm to explain the results\n",
    "llm_explanation = ChatAnthropic(model='claude-3-5-haiku-20241022', temperature=0.5)\n",
    "\n",
    "explanation_template = \"\"\"\n",
    "Explain HubSpot responses in plain language:\n",
    "\n",
    "Format:\n",
    "1. Summary line: \"Found [X] results for [query type]\"\n",
    "2. Bullet-point details for each result\n",
    "3. For errors: Explain issue and solution simply\n",
    "\n",
    "Rules:\n",
    "- Use everyday language\n",
    "- No technical terms (API, JSON, etc.)\n",
    "- Be thorough but simple\n",
    "- No clarification offers\n",
    "- No jargon\n",
    "\n",
    "Style:\n",
    "- Clear\n",
    "- Descriptive\n",
    "- Easy to understand\n",
    "- Direct\n",
    "\n",
    "Response: {response}\n",
    "\n",
    "Use the response to answer the user's query below.\n",
    "\n",
    "Query: {query}\n",
    "\"\"\"\n",
    "\n",
    "explanation_prompt = PromptTemplate(template=explanation_template, input_variables=[\"response\", \"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the explanation chain\n",
    "explanation_chain = LLMChain(\n",
    "    llm=llm_explanation,\n",
    "    prompt=explanation_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Found 1 result for deal associations\n",
      "\n",
      "• One contact is linked to the deal (Deal ID: 28338118010)\n",
      "• The contact's unique ID is 71750622225\n",
      "• This is a standard HubSpot system-defined connection\n",
      "\n",
      "Important Notes:\n",
      "- The response shows a basic association between a contact and the specified deal\n",
      "- Only the contact's ID is provided, not additional contact details\n",
      "- The association type is a standard HubSpot system connection\n",
      "\n",
      "Recommendation:\n",
      "To get full contact details, you would need to make a separate request using the contact ID 71750622225.\n"
     ]
    }
   ],
   "source": [
    "# Run the explanation chain\n",
    "explanation = explanation_chain.run({\n",
    "    \"response\": PythonREPL().run(response['result']),\n",
    "    \"query\": query\n",
    "})\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
