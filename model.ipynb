{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulsingh/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rahulsingh/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "from transformers import LongformerTokenizer, LongformerModel\n",
    "import torch\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Longformer model and tokenizer\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-large-4096')\n",
    "model = LongformerModel.from_pretrained('allenai/longformer-large-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom embedding class with embed_query method\n",
    "class LongformerEmbedding:\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=4096, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().tolist()  # Mean pooling\n",
    "        return embedding\n",
    "\n",
    "# Instantiate the custom embedding class\n",
    "longformer_embedder = LongformerEmbedding(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Pinecone and initialize with the existing index\n",
    "index_name = \"hubspot-crm-txts\"\n",
    "\n",
    "# Initialize PineconeVectorStore with the custom embedding class\n",
    "vector_store = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=longformer_embedder  # Pass the embedding class here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Retrieval Chain with LangChain\n",
    "llm_rag = ChatAnthropic(model='claude-3-5-sonnet-20241022', temperature=0.1)\n",
    "\n",
    "# Define your custom prompt with context and prefix\n",
    "rag_template = \"\"\"\n",
    "    Role: HubSpot API Python Code Generator.\n",
    "\n",
    "    Context:\n",
    "    {text}\n",
    "\n",
    "    Generate Python code that:\n",
    "    - Uses the HubSpot Client Library when possible; falls back to `requests` for unsupported features.\n",
    "    - Returns raw JSON responses only.\n",
    "    - Uses the provided `access_token` and includes necessary imports.\n",
    "    - Ends with `print(response)`.\n",
    "    - Wraps all operations in `try-except` for error handling.\n",
    "    - Avoids comments, docstrings, and markdown.\n",
    "\n",
    "    Special Considerations:\n",
    "    - Filtering:\n",
    "    - Use Client Library filters with correct imports if supported.\n",
    "    - Otherwise, send filter payloads via `requests`.\n",
    "    - Associations:\n",
    "    - Use `requests.get()` for endpoints formatted as:\n",
    "        https://api.hubapi.com/crm/v4/objects/<object_type>/<id>/associations/<to_object_type>.\n",
    "    - Include an `Authorization` header with the Bearer token.\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate(template=rag_template, input_variables=[\"text\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Retrieval-Augmented Generation (RAG) chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_rag,\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs = {\n",
    "        \"prompt\": rag_prompt,\n",
    "        \"document_variable_name\": \"text\"\n",
    "    },   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup simple llm to explain the results\n",
    "llm_explanation = ChatAnthropic(model='claude-3-5-haiku-20241022', temperature=0.5)\n",
    "\n",
    "explanation_template = \"\"\"\n",
    "    Explain the HubSpot response below in plain language to answer the user's query:\n",
    "    \n",
    "    Response: {response}\n",
    "    Query: {query}\n",
    "\n",
    "    Format:\n",
    "    1. Summary line: \"Found [X] results for [query type]\"\n",
    "    2. Bullet-point details for each result\n",
    "    3. For errors (if any): Explain issue and solution simply\n",
    "\n",
    "    Rules:\n",
    "    - Use everyday language\n",
    "    - Be thorough but simple\n",
    "    - No clarification offers\n",
    "    - Instead of saying API request, say \"ask me about\" or \"make a request for\"\n",
    "\n",
    "    Style:\n",
    "    - Clear\n",
    "    - Descriptive\n",
    "    - Easy to understand\n",
    "    - Direct\n",
    "\"\"\"\n",
    "\n",
    "explanation_prompt = PromptTemplate(template=explanation_template, input_variables=[\"response\", \"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the explanation chain\n",
    "explanation_chain = LLMChain(\n",
    "    llm=llm_explanation,\n",
    "    prompt=explanation_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the RAG Chain\n",
    "query = \"tell me about the contacts assoicated with the deal 'HubSpot - New Deal (Sample Deal)'. my access token is pat-na1-59c263ed-698c-4077-b2bc-d1e001750420\"\n",
    "response = rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Found 1 contact associated with the deal\n",
      "\n",
      "Details:\n",
      "• The contact linked to this deal has the ID 71750622225\n",
      "• The association is a standard HubSpot-defined connection (type ID 3)\n",
      "\n",
      "Note: This response only shows the contact ID. To get more specific details about the contact (like name, email), you would need to make another request to retrieve the full contact information using this ID.\n",
      "\n",
      "No errors detected in the response.\n"
     ]
    }
   ],
   "source": [
    "# Run the explanation chain\n",
    "explanation = explanation_chain.run({\n",
    "    \"response\": PythonREPL().run(response['result']),\n",
    "    \"query\": query\n",
    "})\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from hubspot import HubSpot\n",
      "import requests\n",
      "\n",
      "access_token = 'pat-na1-59c263ed-698c-4077-b2bc-d1e001750420'\n",
      "\n",
      "try:\n",
      "    hubspot = HubSpot(access_token=access_token)\n",
      "    \n",
      "    # First get the deal ID by searching for the deal name\n",
      "    filter_dict = {\n",
      "        \"filterGroups\": [{\n",
      "            \"filters\": [{\n",
      "                \"propertyName\": \"dealname\",\n",
      "                \"operator\": \"EQ\",\n",
      "                \"value\": \"HubSpot - New Deal (Sample Deal)\"\n",
      "            }]\n",
      "        }]\n",
      "    }\n",
      "    \n",
      "    deals_response = hubspot.crm.deals.search_api.do_search(\n",
      "        filter_dict\n",
      "    )\n",
      "    \n",
      "    if deals_response.results:\n",
      "        deal_id = deals_response.results[0].id\n",
      "        \n",
      "        # Get associated contacts using requests\n",
      "        url = f\"https://api.hubapi.com/crm/v4/objects/deals/{deal_id}/associations/contacts\"\n",
      "        headers = {\n",
      "            \"Authorization\": f\"Bearer {access_token}\",\n",
      "            \"Content-Type\": \"application/json\"\n",
      "        }\n",
      "        \n",
      "        response = requests.get(url, headers=headers).json()\n",
      "        print(response)\n",
      "        \n",
      "except Exception as e:\n",
      "    print(f\"Error: {str(e)}\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
