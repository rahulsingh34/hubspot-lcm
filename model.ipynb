{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "from transformers import LongformerTokenizer, LongformerModel\n",
    "import torch\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Longformer model and tokenizer\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-large-4096')\n",
    "model = LongformerModel.from_pretrained('allenai/longformer-large-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom embedding class with embed_query method\n",
    "class LongformerEmbedding:\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=4096, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().tolist()  # Mean pooling\n",
    "        return embedding\n",
    "\n",
    "# Instantiate the custom embedding class\n",
    "longformer_embedder = LongformerEmbedding(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Pinecone and initialize with the existing index\n",
    "index_name = \"hubspot-crm-txts\"\n",
    "\n",
    "# Initialize PineconeVectorStore with the custom embedding class\n",
    "vector_store = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=longformer_embedder  # Pass the embedding class here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Retrieval Chain with LangChain\n",
    "llm_rag = ChatAnthropic(model='claude-3-5-sonnet-20241022', temperature=0.1)\n",
    "\n",
    "# Define your custom prompt with context and prefix\n",
    "rag_template = \"\"\"You are a helpful assistant that generates HubSpot API code based on the provided context.\n",
    "Always prioritize information from the context when available.\n",
    "\n",
    "Context: {text}\n",
    "\n",
    "Generate the Python code using the HubSpot Client Library with no comments to answer the following question.\n",
    "You only generate Python code no additional text, comments, docstrings, explanations, syntax code blocks.\n",
    "Use your general knowledge as a helpful assistant if no specific context is provided.\n",
    "Only return code, no additional text. Use the HubSpot Python library where possible.\n",
    "You will be provided with the access_token so be sure to use it. \n",
    "Note that the returned response from your code should be a json object, do not parse it. \n",
    "Your final line should be: print(response), where response is the json object returned from your API call.\n",
    "Do not add a 'limit' parameter within the response unless explicitly asked.\n",
    "If you are asked to filter the data by a specific property, you can create a Filter from the Hubspot Python library. \n",
    "Don't forget to import the proper library for the Filter based on the HubSpot object in question and be sure to use the proper arguments for the API call.\n",
    "Be sure to wrap the code in a try catch block and print the error if any.\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate(template=rag_template, input_variables=[\"text\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Retrieval-Augmented Generation (RAG) chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_rag,\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs = {\n",
    "        \"prompt\": rag_prompt,\n",
    "        \"document_variable_name\": \"text\"\n",
    "    },   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the RAG Chain\n",
    "query = \"what company in my CRM has the domain hubspot.com? my access token is pat-na1-59c263ed-698c-4077-b2bc-d1e001750420\"\n",
    "response = rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Python code\n",
    "python_repl = PythonREPL()\n",
    "repl_response = python_repl.run(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup simple llm to explain the results\n",
    "llm_explanation = ChatAnthropic(model='claude-3-5-haiku-20241022', temperature=0.5)\n",
    "\n",
    "explanation_template = \"\"\"You are a helpful assistant that explains JSON responses from the HubSpot API.\n",
    "Do not use technical terms in your response like API or JSON, explain in plain language. Be descriptive and easy to understand and thorough.\n",
    "Do not offer to provide clarifications at the end of your response.\n",
    "Your response should be formatted as such: an opening line that summarizes the number of results found and what the query was about, then a bullet point list with details about the results.\n",
    "If the response is an error, explain the error and how to fix it in the response.\n",
    "\n",
    "Response: {response}\n",
    "\n",
    "Use the response to answer the user's query below.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "explanation_prompt = PromptTemplate(template=explanation_template, input_variables=[\"response\", \"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the explanation chain\n",
    "explanation_chain = LLMChain(\n",
    "    llm=llm_explanation,\n",
    "    prompt=explanation_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 company with the domain \"hubspot.com\" in your customer relationship management system.\n",
      "\n",
      "Here are the details about this company:\n",
      "• Company ID: 25119084880\n",
      "• Domain: hubspot.com\n",
      "• Created on: October 25, 2024 at 12:05:59 AM\n",
      "• Last modified on: October 25, 2024 at 12:06:19 AM\n",
      "• Current status: Active (not archived)\n",
      "• No specific company name is currently listed in the record\n",
      "\n",
      "The company record exists in your system but does not have a name assigned to it at this time. It was recently created and appears to be a basic entry with minimal information.\n"
     ]
    }
   ],
   "source": [
    "# Run the explanation chain\n",
    "explanation = explanation_chain.run({\n",
    "    \"response\": repl_response,\n",
    "    \"query\": query\n",
    "})\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
